\documentclass[10pt,letterpaper]{article}
\usepackage{color,amsmath,amsthm,amsfonts,graphicx,float,units,subfig,subfloat,hyperref}
\DeclareGraphicsExtensions{.pdf,.png,.jpg}
\graphicspath{{./}}
\begin{document}

\title{HCIPlayer: Project Evolution}
\author{ECSE424 Winter 2010, McGill University}
\renewcommand{\today}{March 24th, 2010}
\maketitle

During the time since the high-fidelity prototype, we have received feedback from user testing as well as from the TAs allowing us to evaluate our prototype's performance. It is necessary to discuss the important observations made by the evaluation team. These assessments also need to be compared to the observations made from our own testing, to gain a better understanding of the utility of the prototype interface.

\section*{Discussion on interface}
To decide what gestures would be acceptable for controlling the device, it was necessary to try several implementations on multiple different people. This test process and subsequent discussion led to our implementation prior to the evaluation team's tests; the added feedback from the evaluation team has helped us make key decisions while building the alpha system. Additionally, discussion with Dalia, and our own reevaluation of the basic goals of the system have helped improve our design. We analyzed the strengths and weaknesses reported by the evaluation team and have adjusted our prototype to address the usability goals as outlined in our benchmark tasks document. Improvements were made in the following areas:

\subsection*{Crashes}
System crashes were reported as rampant in the evaluation, which was unfortunately detrimental to the ability of the group to test the usability of the system. This was clearly seen from the results of the Data Collection Survey. We thus decided to change the interface in order to give the user clearer and more descriptive information regarding a system crash. We believe that system crashes that the evaluation team experienced with the prototype were the result of three main issues, namely
	\begin{enumerate}
	\item
	a weak wireless signal that could have resulted in crashes or states that would be reasonably interpreted as crashes
	\item
	combinations of user inputs that had not yet been accounted for
	\item
	system bugs, often only inconsistently reproducible, which had not yet been removed
	\end{enumerate}
We have been working to remove all of the system crashes reported by the evaluation team in order to construct a more robust alpha system. It is difficult, however, to properly indicate to the user that a total system crash has occurred using the iPhone operating system. In the prototype used during the evaluation, a system bug caused a crash upon startup after each crash, leading to two consecutive crashes regardless of what the user did after startup the second time. This was not a well understood system failure at the time of the evaluation, but this issue has since been fixed.

\subsection*{Visual Feedback}
We are also aware that the user needs to be able to better understand the difference between a system crash and sluggish normal operation. To allow this, we are increasing the amount of both visual and haptic feedback. It is important when adding visual feedback to ensure that we don't do so at the expense of the user experience of the fully blind. Developing a reasonably robust system of visual cues for the visually impaired required a bit of research. Our research into a proper approach eventually led us to this \href{http://www.ted.com/talks/lang/eng/pawan\_sinha\_on\_how\_brains\_learn\_to\_see.html}{TED talk}, which gave us a few ideas for how to go about the design.
\\ \\
This information resulted in us implementing a moving symbol as an easily recognizable visual cue to indicate that the system is processing and will need additional time to compute. The visual cue chosen is a circle moving in a circular path around the center of the screen. We intend to test additional moving visual cues to see which implementations of moving visual cues work best, possibly offering room for more information to be conveyed. These improvements utilize the iPhone screen and are able to provide useful feedback to a substantial population of our target users, hopefully alleviating some of the ambiguity present in the processing state without causing a detriment to its usability for blind individuals.

Additionally, we have decided to pay more attention to the text and images displayed on the screen during normal operation, which previously had only been for our own debugging purposes. For example, while we were demonstrating our prototype to Dalia, it was unclear if the device was paused or muted. While we have decided to get rid of the mute functionality (as explained later), we still think that displaying more status on the screen would be beneficial. Our alpha system now displays a large white ``play'' icon when playing, and a large red ``stop'' icon when the music is stopped. This will require more testing, especially with our assigned visually-impaired individual, to determine how easily these cues can be distinguished.

Our increased focus on visual feedback during this last round of testing have led us to consider some more interesting uses for the music player. We think it would be interesting to add a feature which supported music library navigation without the often clumsy voice commands followed by audio feedback. If time permits, we are considering implementing a quick prototype of this to see if it can improve the usability of the music player.

\subsection*{Redundant Feedback}
We believe the player can be made more intuitive by giving the user additional feedback on many different states of operation. With a wide range of use cases which may vary across our range of target users, redundancy of feedback across a number of modes can be beneficial. Since visual feedback should remain exceptionally macroscopic in detail in order to remain accessible to a large gambit of the visually impaired, we are limited in the range of visual cues that can be implemented. Regardless, it is important to include many audio, tactile, and visual cues to assist the user.

\subsection*{Clutter}
A lot of thought was put into what features actually add real value to the player, as opposed to just taking space in the user manual or even getting in the way of normal operation. It was determined that a gesture for ``\textit{mute}'' fit nicely in latter category, providing an additional (not easily distinguishable) gesture for the system to mistake for something else. In only negligible realistic cases would a mute function be preferable to an easily accessible ``\textit{pause}'' button. It was therefore removed.
\\ \\ 
The question is not so simple when it comes to speech commands that may or may not be necessary. As so many more commands can be used while retaining a high rate of recognition, it seems like the having e.g. ``\textit{previous}'' and ``\textit{next}'' commands available through speech would not hurt the system's usability. It is nearly always easier to use the gesture, as the system requires that the user put a finger on the screen for speech recognition anyways. Realistically, removing commands such as these from the voice recognition system would not significantly improve its ease of use, but could potentially severely reduce it if any user attempted to tell the player `next' with no response. Like with a number of verbal commands in the system, we have opted for the safer road of redundancy, in hopes that it may, if only in a few cases, improve the usability of the system. As such, we have decided to keep these commands.

\subsection*{Tutorial}
Team Ocelot's device featured a brief tutorial, an automated hands-on walkthrough of the device, which we found to be an especially easy way to learn the basic ins and outs of the device, especially for a visually impaired user who may struggle with a printed manual. As such, a tutorial system has been added to the Player to better instruct new users. This makes it simpler for the Player to accommodate a wide range of technical familiarity with portable music players. The evaluation team suggested that our documentation was unclear and a trial-and-error approach eventually prevailed. While we have improved our documentation to address this issue, we also see opportunity to cater even better to first time users.

\end{document}
